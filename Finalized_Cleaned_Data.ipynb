{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf-5LRbexF7f",
        "outputId": "6c5f4540-ffa5-4149-f2be-8e2833b855de"
      },
      "id": "sf-5LRbexF7f",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the raw csv of all storms\n",
        "data = pd.read_csv(\"/content/drive/My Drive/GDToT/ECO482_Project/Data/raw_storm_data.csv\")"
      ],
      "metadata": {
        "id": "iMJYVmgUxdz8"
      },
      "id": "iMJYVmgUxdz8",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping columns that aren't useful\n",
        "pd.set_option('display.max_columns', None)\n",
        "data = data.drop(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH', 'END_DAY', 'END_TIME', 'DATA_SOURCE', 'DURATION',\n",
        "              'DURATION_MINS', 'WFO', 'SOURCE', 'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'YEAR', 'MONTH_NAME',\n",
        "              'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE', 'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE', 'BEGIN_AZIMUTH',\n",
        "              'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH', 'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON'], axis=1)"
      ],
      "metadata": {
        "id": "3mVj6oKVyOT4"
      },
      "id": "3mVj6oKVyOT4",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping all rows with null values for TOR_F_SCALE\n",
        "data = data.dropna(subset=['TOR_F_SCALE'])\n",
        "\n",
        "#dropping all rows where TOR_F_SCALE is not on the EF scale\n",
        "EF_SCALE = ['EF0', 'EF1', 'EF2', 'EF3', 'EF4', 'EF5', 'EFU']\n",
        "data = data[data['TOR_F_SCALE'].astype(str).isin(EF_SCALE)]"
      ],
      "metadata": {
        "id": "czBoElXlzDaN"
      },
      "id": "czBoElXlzDaN",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a sentiment index based on event and episode narrative text columns\n",
        "\n",
        "!pip install pandas textblob nltk afinn\n",
        "import nltk\n",
        "from afinn import Afinn\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Ensure required nltk data is downloaded\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "afinn = Afinn()\n",
        "\n",
        "#function to compute sentiment scores\n",
        "def analyze_sentiment(text):\n",
        "    # TextBlob sentiment (polarity ranges from -1 to 1)\n",
        "    blob_score = TextBlob(text).sentiment.polarity\n",
        "\n",
        "    # AFINN sentiment (ranges from negative to positive integer scores)\n",
        "    afinn_score = afinn.score(text)\n",
        "\n",
        "    return pd.Series([blob_score, afinn_score], index=['TextBlob_Score', 'AFINN_Score'])\n",
        "\n",
        "\n",
        "data[['TextBlob_Score', 'AFINN_Score']] = data['EVENT_NARRATIVE'].str.lower().apply(analyze_sentiment)"
      ],
      "metadata": {
        "id": "X0cVvVx8_0vi",
        "outputId": "0aa60c44-39ee-45c0-c794-0b58f519b386",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "X0cVvVx8_0vi",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: afinn in /usr/local/lib/python3.11/dist-packages (0.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dummy variables out of categories\n",
        "data = pd.DataFrame(pd.get_dummies(data, columns=['STATE', 'CZ_TYPE', 'CZ_NAME', 'CZ_TIMEZONE', 'TOR_F_SCALE']))\n",
        "\n",
        "#converting to 0,1\n",
        "for col in data.columns:\n",
        "    if data[col].dtype == 'bool':  # Check if column is boolean\n",
        "        data[col] = data[col].astype(int)"
      ],
      "metadata": {
        "id": "4eu-YwQiGbHS"
      },
      "id": "4eu-YwQiGbHS",
      "execution_count": 86,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}